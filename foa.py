# -*- coding: utf-8 -*-
import re
from simhash import Simhash, SimhashIndex
from nltk import word_tokenize
from nltk.corpus import stopwords
import nltk
from nltk.stem import SnowballStemmer
from nltk.tokenize import wordpunct_tokenize
import string
from nltk.stem import PorterStemmer, WordNetLemmatizer
import operator
from collections import OrderedDict
from operator import itemgetter
import pprint


def find_distance(s1, s2):
    return Simhash(s1).distance(s2)


def stop_words_removal(doc):
    doc.decode('ascii', 'ignore')
    doc = doc.translate(None, string.punctuation)
    stop = set(stopwords.words('english'))
    words = [i for i in doc.lower().split() if i not in stop]
    return ' '.join(words).decode('ascii', 'ignore').encode('utf-8')


def tokenize(text):
    snowball_stemmer = SnowballStemmer('english')
    wnl = WordNetLemmatizer() #Stemming
    return ([snowball_stemmer.stem(itr) for itr in text.split()])

### TO CREATE HASH MAP FOR A DOCUMENT WITH FREQUENCY OF WORDS AND EACH WORDS OCCURENCE###
def create_hash_count(text):
    occurences = {}
    count = {}
    size = len(text)
    itr = 0
    while(itr<size):
        if text[itr] in occurences:
            occurences[text[itr]].append(itr)
            count[text[itr]] += 1
        else:
            occurences[text[itr]] = [itr]
            count[text[itr]] = 1
        itr += 1
    count = OrderedDict(sorted(count.items(), key=itemgetter(1),reverse=True))
    return (occurences,count)

### PREPROCESSING OF A DOCUMENT ###
def pre_processing(doc):
    result = stop_words_removal(doc)
    resultant_text = tokenize(result)
    # occurences,count = create_hash_count(resultant_text)
    # return occurences,count,resultant_text
    return resultant_text


def main_method():
    
    #doc3 = "British Sugar Plc was forced to shut its Ipswich sugar factory on Sunday afternoon due to an acute shortage of beet supplies, a spokesman said, responding to a Reuter inquiry.Beet supplies have dried up at Ipswich due to a combination of very wet weather, which has prevented most farmers in the factory's catchment area from harvesting, and last week's hurricane which blocked roads.The Ipswich factory will remain closed until roads are cleared and supplies of beet build up again.This is the first time in many years that a factory has been closed in mid-campaign, the spokesman added.Other factories are continuing to process beet normally, but harvesting remains very difficult in most areas.Ipswich is one of 13 sugar factories operated by British Sugar. It processes in excess of 500,000 tonnes of beet a year out of an annual beet crop of around eight mln tonnes. Despite the closure of Ipswich and the severe harvesting problems in other factory areas, British Sugar is maintaining its estimate of sugar production this campaign at around 1.2 mln tonnes, white value, against 1.34 mln last year, the spokesman said. British Sugar processes all sugar beet grown in the U.K. The sugar beet processing campaign, which began last month, is expected to run until the end of January. Sugar factories normally work 24 hours a day, seven days a week during the campaign.As of October 11, 12 pct of the U.K. Sugar crop had been harvested, little different to the same stage last year when 13 pct had been lifted. Since then, however, very wet weather has severely restricted beet lifting. Harvesting figures for the week to October 18 are not yet available."
    #doc2 = "British Sugar Plc was forced to shut its Ipswich sugar factory on Sunday afternoon due to an acute shortage of beet supplies, a spokesman said, responding to a Reuter inquiry.Beet supplies have dried up at Ipswich due to a combination of very wet weather, which has prevented most farmers in the factory's catchment area from harvesting, and last week's hurricane which blocked roads.The Ipswich factory will remain closed until roads are cleared and supplies of beet build up again.This is the first time in many years that a factory has been closed in mid-campaign, the spokesman added.Other factories are continuing to process beet normally, but harvesting remains very difficult in most areas.Ipswich is one of 13 sugar factories operated by British Sugar. It processes in excess of 500,000 tonnes of beet a year out of an annual beet crop of around eight mln tonnes. Despite the closure of Ipswich and the severe harvesting problems in other factory areas, British Sugar is maintaining its estimate of sugar production this campaign at around 1.2 mln tonnes, white value, against 1.34 mln last year, the spokesman said. British Sugar processes all sugar beet grown in the U.K. The sugar beet processing campaign, which began last month, is expected to run until the end of January. Sugar factories normally work 24 hours a day, seven days a week during the campaign.As of October 11, 12 pct of the U.K. Sugar crop had been harvested, little different to the same stage last year when 13 pct had been lifted. Since then, however, very wet weather has severely restricted beet lifting. Harvesting figures for the week to October 18 are not yet available."
    #doc = "British Sugar Plc was forced to shut its Ipswich sugar factory on Sunday afternoon due to an acute shortage of beet supplies, a spokesman said, responding to a Reuter inquiry.Beet supplies have dried up at Ipswich due to a combination of very wet weather, which has prevented most farmers in the factory's catchment area from harvesting, and last week's hurricane whi"
    #doc5 = "Representatives of U.S. sugar grower organizations said they expect some increase the area planted to sugarbeets this year and said the prospects for the 1987 cane sugar crop also are good. Dave Carter, president of the U.S. beet sugar association, said plantings may be up in two major beet growing states, California and Michigan, while sowings could be down slightly in the largest producing state of Minnesota. Overall, Carter predicted beet plantings would rise in the midwest, and this coupled with increases in California would increase U.S. sugarbeet plantings slightly from the 1.232 mln acres sown last year. USDA later today releases its first estimate of 1987 U.S. sugarbeet plantings in the prospective plantings report. The main reason for the expected increase in beet sowings is that returns from competing crops such as soybeans and grains are just awful said Carter. In the midwest, bankers are strongly encouraging farmers to plant sugarbeets because the U.S. sugar program offers a loan rate of 18 cents per pound and because payments to farmers from beet processors are spread evenly over the growing season, said Luther Markwart, executive vice president of the American sugarbeet growers association. The banks are putting a lot of pressure on these guys, Markwart said. In some areas there are waiting lists of farmers seeking a contract with processors to plant beets, Markwart said. USDA's report today will not include any harvested area estimates for sugarcane, but representatives of Florida, Hawaii and Louisiana growers said crop prospects are good. Horis Godfrey, a consultant representing Florida and Texas cane growers"
    #doc33 = "British Plc was forced to shut its Ipswich sugar factory version Sunday afternoon due to an acute shortage of beet supplies database imaging image"
    #doc55 = "Representatives of U.S. sugar factory version said they expect some increase the area planted to sugarbeets this year"
    #pp = 'SREPT Most of the software reliability tools are concentrated at exploiting the functioning of a software during a specific lifecycle of software development phase and have a defined set of steps that they follow drilling down a specific area of the software. Software Reliability and Prediction Tool is a proposed deign of a software tool to predict reliability at all levels of software life-cycle, including architecture / design phases. The proposed design of the software supports Black Box testing and Architecture Based testing. Black Box Testing Inputs and Outputs to Black Box Testing are as follows: Complexity Metrics \xe2\x80\x93 Based on the no of lines of code, loops, decisions, conditions etc. This gives an estimate of number of errors as an output. The tool uses Fault Density approach or Regression Tree approach to calculate the count. Test Coverage \xe2\x80\x93 Is a parameter defined by the number of test areas covered by a given input test case as opposed to the total test areas. Interfailure times \xe2\x80\x93 can be defined as mean times between failures while testing the software. The interfailure times acts as an input parameter to ENHPP (Enhanced Non-Homogeneous Poisson Process) model to estimate fault intensity, remaining fault counts, reliability after release and test coverage. Release Criteria \xe2\x80\x93 is defined by the criteria which needs to be fulfilled to release the software. The criteria can be based on number of remaining faults, failure intensity requirements, reliability requirements, cost requirements or availability requirements. Interfailure times and release criteria acts as an input parameter to ENHPP model to help calculate release time and code coverage. ENHPP assumes instantaneous debugging of detected faults. Remedy is to add debugging rate as an affecting parameter to failure intensity. Debugging rate can be calculated using state-space method or discrete event simulation, where the latter method is preferred.Architecture Based Approach This is one of the differentiating factor of SREPT, which assumes that a modern day software is made of multiple modules present anywhere on the globe and proposes failure testing strategy to test interoperability of these modules.Architecture of a software: This approach deals with ways and techniques by which various modules of a software interact, and evaluates failure rate caused due to these interactions or while transfer of a control from one module to another. This approach uses Markov Chain Models (DTMC, CTMC, SMC) and Directed Acyclic Graphs to perform the said operations to calculate failure rates. The implementations are classified into irreducible (infinitely running application) and absorbing (terminating in finite time) categories. The output parameters given by these models are majorly the number of visits to a component, time spent on a particular component and total time taken for application execution.Failure Behavior: This approach closely analyses the failure behavior of the modules and of the interfaces between them, to calculate probability of failure and failure rate etc for these modules. Failure rates are affected mainly in cases where transitions between modules take a certain finite amount of time and does not occur instantly. Using a combination of architecture model and failure behavior of a software, one can develop a composite model to help determine reliability of the software. The paper also discusses about a hierarchical model, where the architecture model is implemented first and the failure behavior is tested on the output / solution of the architecture model to determine reliability. SMERFS SMERFS (Statistical Modelling and Estimation of Software Reliability Functions) is another tool for testing software reliability helping predict ideal time to release the software. A major difference of this tool as compared to SREPT is that the former specializes in detecting faults only during the testing phase of software life-cycle. Following are the input / output parameters to SMERFS: Failure History Data \xe2\x80\x93 isthe data on which the tool would operate to generate reliability estimates and predictions. Data type \xe2\x80\x93 would bear information about the type of data, which would act as one of the validating criteria for generating estimates. Assumptions \xe2\x80\x93 is an input to SMERFS used when user performs a query operation to fetch characteristics of a specified software reliability model. Output \xe2\x80\x93 would have the history data generated by the tool, which can potentially be used to evaluate other software models in the future. Both approaches have their own advantages and disadvantages. SREPT has a broader impact due to its applicability at multiple phases in a software life-cycle. SMERFS provides an in-depth analysis of a software targeting only the testing phase. One must keep in mind the pros and cons of each tool and the goals they want to achieve to be able to efficiently use the tools and release an error free product.'
    #plag = 'Black Box Testing Inputs and Outputs to Black Box Testing are as follows: Complexity Metrics \xe2\x80\x93 Based on the no of lines of code, loops, decisions, conditions etc. This gives an estimate of number of errors as an output. The tool uses Fault Density approach or Regression Tree approach to calculate the count. Test Coverage \xe2\x80\x93 Is a parameter defined by the number of test areas covered by a given input test case as opposed to the total test areas. Interfailure times \xe2\x80\x93 can be defined as mean times between failures while testing the software. The criteria can be based on number of remaining faults, failure intensity requirements, reliability requirements, cost requirements or availability requirements. Interfailure times and release criteria acts as an input parameter to ENHPP model to help calculate release time and code coverage. ENHPP assumes instantaneous debugging of detected faults. Remedy is to add debugging rate as an affecting parameter to failure intensity. Debugging rate can be calculated using state-space method or discrete event simulation, where the latter method is preferred.Architecture Based Approach This is one of the differentiating factor of SREPT, which assumes that a modern day software is made of multiple modules present anywhere on the globe and proposes failure testing strategy to test interoperability of these modules.Architecture of a software: This approach deals with ways and techniques by which various modules of a software interact, and evaluates failure rate caused due to these interactions or while transfer of a control from one module to another. This approach uses Markov Chain Models (DTMC, CTMC, SMC) and Directed Acyclic Graphs to perform the said operations to calculate failure rates. The output parameters given by these models are majorly the number of visits to a component, time spent on a particular component and total time taken for application execution.Failure Behavior: This approach closely analyses the failure behavior of the modules and of the interfaces between them, to calculate probability of failure and failure rate etc for these modules. Failure rates are affected mainly in cases where transitions between modules take a certain finite amount of time and does not occur instantly. Using a combination of architecture model and failure behavior of a software, one can develop a composite model to help determine reliability of the software.'
    #pp1 = 'The two reliability prediction approaches, SREPT and SMERFS (cubed) are tools that measure the reliability of software in different ways and the table below compares and contrasts both approaches. The design and architecture for SREPT is understood [1] from and SMURFS (cubed) is understood through the document [2] that explores software reliability carried out by Software Assurance Technology Center at the NASA Goddard Space Flight Center. Introduction It is a unified framework containing techniques that evaluate software reliability at all phases of the software lifecycle by using the black-box approach and the architecture approach. SMERFS uses raw historical data and analyses it using various models to predict the future behavior of the system based on its past trends. INPUTS :At a time, the input type to the tool can be one of these- inter-failure times data only, inter-failure times and coverage data, or estimated # faults and coverage data. There are only two kinds of inputs: time-between-failure and interval data which is provided in the form of text files in the specified formatting of the data in the files. MODELS One of the several models can be used in the black-box approach for estimating the outputs such as the fault density approach and regression tree model for estimating the number of faults which is also one of the inputs to the ENHPP model to estimate the failure intensity, number of faults remaining and reliability after release. Also, the NHCTMC model can be used for the same. For the architectural approach, the operational profile of the software can be modeled as a DTMC, CTMC etc. SMERFS has fixed models contained for the two types of inputs. The selection of the appropriate models is done based on a project\xe2\x80\x99s characteristics by an analyst or it can also allow SMERFS to select the models that are appropriate. All interval data models use the same input and all time-between-failure models use the same. OUTPUTS The analysis of explicit fault removal is done using the state-space method and discrete event simulation for the black-box approach. Failure occurrence and debugging rates are used to estimate failure intensity, number of faults and reliability after release as the output. For the output the tool generates a chart for each of the models selected, with the estimates of total faults and total faults remaining that are produced by the models. The queries are slightly Thus, from the above table we compare the different properties of the two reliability modelling and prediction approaches. SREPT implements and takes into account several more software reliability techniques such as the complexity metrics used in the pretest phase, inter-failure times based technique and architecture based techniques as well that model the different components of the software. SMURFS^3 takes only two types of inputs into consideration and is rather a tool that shows that software tools can perform most of the mathematical and statistical functions of software reliability modeling without the analyst or tester having a deep understanding of mathematics. In conclusion, these tools give a promising approach to software reliability measurement by modelling the software reliability and evaluate the quality of the overall software development process. '
    #pp2 = 'INTRODUCTION The following essay compares the two reliability prediction techniques \xe2\x80\x93 Software Reliability Estimation and Prediction tool and Statistical Modeling and Estimation of Reliability Functions for Systems tool. Reliability prediction is one of the most common forms of reliability analysis and the predict the failure rate of components and overall system reliability. These predictions can then help in the evaluation of the design feasibility, comparison of the other design alternatives there are, identify the failure areas as well track the reliability improvement. SREPT: Many tools that are available are highly specialized in their approaches but focus on a particular phase of the software life-cycle. SREPT: Software Reliability Estimation and Prediction tool offers a unified framework containing techniques to assist in the evaluation of software reliability at all phases of the software life-cycle. It also uses an architecture based approach which is essential to predict the reliability and performance of heterogeneous systems. SMERFS [CUBED]: The purpose of developing SMERFS was that the software reliability methodology required sophisticated numerical procedures to obtain estimates of the model parameters. SMERFS CUBED is an application that allows the users to do hardware, software or total system reliability analysis. SMERFS CUBED aims to provide and thus allows the user to do both component and systems level assessment. INPUTS: SREPT: The SREPT tool follows two approaches: Black Box Based Approach: The black box approach treats the software as one entity and does not take into consideration the internal structure of the software. The Black Box based approach predicts the results based on the following inputs: Complexity metrics: Example: lines of code, number of decisions, loops, mean length of variable names and other such static attributes of the code. Test Coverage: The ratio of potential fault sites that the test cases covered in the code to the total number of potential fault sites in the code. Inter-failure Times data: This is the observed times between failures. Architecture Based Approach:  This approach uses the internal control structure of the software.  The reliability of the software is predicted based on the following inputs: Architecture of the software: The input given here is the specification of how the modules in the software interact with each other. This can be depicted with the help of state transition between the module and transfer of control. Failure Behavior: This attribute is used to define the failure behavior of the components. SMERFS [CUBED]: SMERFS CUBED provides software, hardware and system reliability analysis, the inputs are given in the form of a data set as follows: Software analysis: To do a reliability analysis based on the time between errors the input format is of two columns: elapsed time and whether a software failure has occurred. To do a reliability analysis based on the Interval Counts the input format is of two columns: Software error count and the length of the interval.  Hardware Analysis: To do a reliability analysis based on the time between errors the input format is of five columns: time between the failure, the failure type, the severity level and the hardware number and the hardware efficiency factor between 0 and 1. System Analysis: To do a reliability analysis based on the time between errors the input format is of three columns: time between the failure, the failure type, the severity level.OUTPUTS: SREPT:This tool gives outputs such as Estimation of number of faults, failure intensity, number of faults remaining, reliability after release in the black box approach and in the architecture based approach gives reliability and performance measure such as expected number of visits to a component, the average time spent in a component and the time to completion. The tool also allows the user to plot the results based on what has been detected and the predictions of the tool. SMERFS [CUBED]: Based on the input of the data, the tool gives a list of models that could be a proper fit for their data and also gives the models that cannot fit. On selecting a particular model, the tool the provides estimation of the data for the model, predictions like remaining number of errors, mean time-to-failure, expected number of fault detections over the next testing period, projected operational reliability. And also plots the original data to the predicted data. The tool also provides an accuracy for the data and the accuracy of the fit when each model is used. ASSUMPTIONS: SREPT: The ENHPP techniques described in SREPT assume instantaneous debugging of the faults detected during the tests which is unrealistic and causes estimates that are optimistic.'
    #test_data = 'The two reliability prediction approaches, SREPT and SMERFS (cubed) are tools that measure the reliability of software in different ways and the table below compares and contrasts both approaches. The design and architecture for SREPT is understood [1] from and SMURFS (cubed) is understood through the document [2] that explores software reliability carried out by Software Assurance Technology Center at the NASA Goddard Space Flight Center. Introduction It is a unified framework containing techniques that evaluate software reliability at all phases of the software lifecycle by using the black-box approach and the architecture approach. SMERFS uses raw historical data and analyses it using various models to predict the future behavior of the system based on its past trends. INPUTS :At a time, the input type to the tool can be one of these- inter-failure times data only, inter-failure times and coverage data, or estimated # faults and coverage data. There are only two kinds of inputs: time-between-failure and interval data which is provided in the form of text files in the specified formatting of the data in the files. MODELS One of the several models can be used in the black-box approach for estimating the outputs such as the fault density approach and regression tree model for estimating the number of faults which is also one of the inputs to the ENHPP model to estimate the failure intensity, number of faults remaining and reliability after release. Also, the NHCTMC model can be used for the same. For the architectural approach, the operational profile of the software can be modeled as a DTMC, CTMC etc. SMERFS has fixed models contained for the two types of inputs. The selection of the appropriate models is done based on a project’s characteristics by an analyst or it can also allow SMERFS to select the models that are appropriate. All interval data models use the same input and all time-between-failure models use the same. OUTPUTS The analysis of explicit fault removal is done using the state-space method and discrete event simulation for the black-box approach. Failure occurrence and debugging rates are used to estimate failure intensity, number of faults and reliability after release as the output. For the output the tool generates a chart for each of the models selected, with the estimates of total faults and total faults remaining that are produced by the models. The queries are slightly Thus, from the above table we compare the different properties of the two reliability modelling and prediction approaches. SREPT implements and takes into account several more software reliability techniques such as the complexity metrics used in the pretest phase, inter-failure times based technique and architecture based techniques as well that model the different components of the software. SMURFS takes only two types of inputs into consideration and is rather a tool that shows that software tools can perform most of the mathematical and statistical functions of software reliability modeling without the analyst or tester having a deep understanding of mathematics. In conclusion, these tools give a promising approach to software reliability measurement by modelling the software reliability and evaluate the quality of the overall software development process. '
    #test_data1 = 'The two reliability prediction approaches, SREPT and SMERFS (cubed) are tools that measure the reliability of software in different ways and the table below compares and contrasts both approaches. The design and architecture for SREPT is understood [1] from and SMURFS (cubed) is understood through the document [2] that explores software reliability carried out by Software Assurance Technology Center at the NASA Goddard Space Flight Center. Introduction It is a unified framework containing techniques that evaluate software reliability at all phases of the software lifecycle by using the black-box approach and the architecture approach. SMERFS uses raw historical data and analyses it using various models to predict the future behavior of the system based on its past trends. INPUTS :At a time, the input type to the tool can be one of these- inter-failure times data only, inter-failure times and coverage data, or estimated # faults and coverage data. There are only two kinds of inputs: time-between-failure and interval data which is provided in the form of text files in the specified formatting of the data in the files. MODELS One of the several models can be used in the black-box approach for estimating the outputs such as the fault density approach and regression tree model for estimating the number of faults which is also one of the inputs to the ENHPP model to estimate the failure intensity, number of faults remaining and reliability after release. Also, the NHCTMC model can be used for the same. For the architectural approach, the operational profile of the software can be modeled as a DTMC, CTMC etc. SMURFS takes only two types of inputs into consideration and is rather a tool that shows that software tools can perform most of the mathematical and statistical functions of software reliability modeling without the analyst or tester having a deep understanding of mathematics. In conclusion, these tools give a promising approach to software reliability measurement by modelling the software reliability and evaluate the quality of the overall software development process.'
    #test_data2 = 'The two reliability prediction approaches, SREPT and SMERFS (cubed) are tools that measure the reliability of software in different ways and the table below compares and contrasts both approaches. The design and architecture for SREPT is understood [1] from and SMURFS (cubed) is understood through the document [2] that explores software reliability carried out by Software Assurance Technology Center at the NASA Goddard Space Flight Center. Introduction It is a unified framework containing techniques that evaluate software reliability at all phases of the software lifecycle by using the black-box approach and the architecture approach. SMERFS uses raw historical data and analyses it using various models to predict the future behavior of the system based on its past trends. INPUTS :At a time, the input type to the tool can be one of these- inter-failure times data only, inter-failure times and coverage data, or estimated # faults and coverage data. There are only two kinds of inputs: time-between-failure and interval data which is provided in the form of text files in the specified formatting of the data in the files. MODELS One of the several models can be used in the black-box approach for estimating the outputs such as the fault density approach and regression tree model for estimating the number of faults which is also one of the inputs to the ENHPP model to estimate the failure intensity, number of faults remaining and reliability after release. Also, the NHCTMC model can be used for the same. For the architectural approach, the operational profile of the software can be modeled as a DTMC, CTMC etc. ENHPP assumes instantaneous debugging of detected faults. Remedy is to add debugging rate as an affecting parameter to failure intensity. Debugging rate can be calculated using state-space method or discrete event simulation, where the latter method is preferred.Architecture Based Approach This is one of the differentiating factor of SREPT, which assumes that a modern day software is made of multiple modules present anywhere on the globe and proposes failure testing strategy to test interoperability of these modules.Architecture of a software: This approach deals with ways and techniques by which various modules of a software interact, and evaluates failure rate caused due to these interactions or while transfer of a control from one module to another. This approach uses Markov Chain Models (DTMC, CTMC, SMC) and Directed Acyclic Graphs to perform the said operations to calculate failure rates. The implementations are classified into irreducible (infinitely running application) and absorbing (terminating in finite time) categories. The output parameters given by these models are majorly the number of visits to a component, time spent on a particular component and total time taken for application execution.Failure Behavior SMURFS takes only two types of inputs into consideration and is rather a tool that shows that software tools can perform most of the mathematical and statistical functions of software reliability modeling without the analyst or tester having a deep understanding of mathematics. In conclusion, these tools give a promising approach to software reliability measurement by modelling the software reliability and evaluate the quality of the overall software development process."
    doc1 = """British Sugar Plc was forced to shut its Ipswich sugar factory on Sunday afternoon due to an acute shortage of beet 
            supplies, a spokesman said, responding to a Reuter inquiry     Beet supplies have dried up at Ipswich due to a combination 
            of very wet weather, which has prevented most farmers in the factory's catchment area from harvesting, and last week's 
            hurricane which blocked roads.The Ipswich factory will remain closed until roads are cleared and supplies of beet build up again.     
            This is the first time in many years that a factory has been closed in mid-campaign, the spokesman added.     
            Other factories are continuing to process beet normally, but harvesting remains very difficult in most areas.    
             Ipswich is one of 13 sugar factories operated by British Sugar. It processes in excess of 500,000 tonnes of beet a year
              out of an annual beet crop of around eight mln tonnes.Despite the closure of Ipswich and the severe harvesting problems in 
              other factory areas, British Sugar is maintaining its estimate of sugar production this campaign at around 1.2 mln tonnes, 
              white value, against 1.34 mln last year, the spokesman said.     British Sugar processes all sugar beet grown in the U.K.     
              The sugar beet processing campaign, which began last month, is expected to run until the end of January. Sugar factories normally 
              work 24 hours a day, seven days a week during the campaign.     As of October 11, 12 pct of the U.K. Sugar crop had been harvested, 
              little different to the same stage last year when 13 pct had been lifted. Since then, however, very wet weather has severely restricted 
              beet lifting. Harvesting figures for the week to October 18 are not yet available."""

    doc2 = """Responding to a Reuter inquiry, a spokesman said that due to an acute shortage of beet 
            supplies, British Sugar Plc was forced to shut its Ipswich sugar factory on Sunday afternoon. Beet supplies have dried up at Ipswich due to a combination 
            of very wet weather, which has prevented most farmers in the factory's catchment area from harvesting, and last week's 
            hurricane which blocked roads. The head of the provincial food agency said,Indonesia has imported 12,000 tonnes of
            refined sugar from Cuba to meet consumer demand in the province
            of South Sulawesi. Because two of three sugar
            refineries in the province have been temporarily shut down, the imported sugar was needed. It
            arrived in the provincial capital of Ujungpandang today and
            will be distributed to markets in the province, the food agency
            official said. Ibut harvesting remains very difficult in most areas.    
             Ipswich is one of 13 sugar factories operated by British Sugar. Out of an annual beet crop of around eight mln tonnes, It processes in excess of 500,000 tonnes of beet a year. Despite the closure of Ipswich and the severe harvesting problems in 
              other factory areas, British Sugar is maintaining its estimate of sugar production this campaign at around 1.2 mln tonnes, 
              white value, against 1.34 mln last year, the spokesman said.     British Sugar processes all sugar beet grown in the U.K.     
              The sugar beet processing campaign, which began last month, is expected to run until the end of January. Sugar factories normally 
              work 24 hours a day, seven days a week during the campaign. Little different to the same stage last year when 13 pct had been lifted, as of October 11, 12 pct of the U.K. Sugar crop had been harvested.
         Since then, however, very wet weather has severely restricted 
             beet lifting. Harvesting figures for the week to October 18 are not yet available"""

    document1 = """INTRODUCTION The following essay compares the two reliability prediction techniques \xe2\x80\x93 Software Reliability Estimation and Prediction tool and Statistical Modeling and Estimation of Reliability Functions for Systems tool. Reliability prediction is one of the most common forms of reliability analysis and the predict the failure rate of components and overall system reliability. These predictions can then help in the evaluation of the design feasibility, comparison of the other design alternatives there are, identify the failure areas as well track the reliability improvement. SREPT: Many tools that are available are highly specialized in their approaches but focus on a particular phase of the software life-cycle. SREPT: Software Reliability Estimation and Prediction tool offers a unified framework containing techniques to assist in the evaluation of software reliability at all phases of the software life-cycle. It also uses an architecture based approach which is essential to predict the reliability and performance of heterogeneous systems. SMERFS [CUBED]: The purpose of developing SMERFS was that the software reliability methodology required sophisticated numerical procedures to obtain estimates of the model parameters. SMERFS CUBED is an application that allows the users to do hardware, software or total system reliability analysis. SMERFS CUBED aims to provide and thus allows the user to do both component and systems level assessment. INPUTS: SREPT: The SREPT tool follows two approaches: Black Box Based Approach: The black box approach treats the software as one entity and does not take into consideration the internal structure of the software. The Black Box based approach predicts the results based on the following inputs: Complexity metrics: Example: lines of code, number of decisions, loops, mean length of variable names and other such static attributes of the code. Test Coverage: The ratio of potential fault sites that the test cases covered in the code to the total number of potential fault sites in the code. Inter-failure Times data: This is the observed times between failures. Architecture Based Approach:  This approach uses the internal control structure of the software.  The reliability of the software is predicted based on the following inputs: Architecture of the software: The input given here is the specification of how the modules in the software interact with each other. This can be depicted with the help of state transition between the module and transfer of control. Failure Behavior: This attribute is used to define the failure behavior of the components. SMERFS [CUBED]: SMERFS CUBED provides software, hardware and system reliability analysis, the inputs are given in the form of a data set as follows: Software analysis: To do a reliability analysis based on the time between errors the input format is of two columns: elapsed time and whether a software failure has occurred. To do a reliability analysis based on the Interval Counts the input format is of two columns: Software error count and the length of the interval.  Hardware Analysis: To do a reliability analysis based on the time between errors the input format is of five columns: time between the failure, the failure type, the severity level and the hardware number and the hardware efficiency factor between 0 and 1. System Analysis: To do a reliability analysis based on the time between errors the input format is of three columns: time between the failure, the failure type, the severity level.OUTPUTS: SREPT:This tool gives outputs such as Estimation of number of faults, failure intensity, number of faults remaining, reliability after release in the black box approach and in the architecture based approach gives reliability and performance measure such as expected number of visits to a component, the average time spent in a component and the time to completion. The tool also allows the user to plot the results based on what has been detected and the predictions of the tool. SMERFS [CUBED]: Based on the input of the data, the tool gives a list of models that could be a proper fit for their data and also gives the models that cannot fit. On selecting a particular model, the tool the provides estimation of the data for the model, predictions like remaining number of errors, mean time-to-failure, expected number of fault detections over the next testing period, projected operational reliability. And also plots the original data to the predicted data. The tool also provides an accuracy for the data and the accuracy of the fit when each model is used. ASSUMPTIONS: SREPT: The ENHPP techniques described in SREPT assume instantaneous debugging of the faults detected during the tests which is unrealistic and causes estimates that are optimistic."""
    document2 = """Representatives of U.S. sugar grower organizations said they expect some increase the area planted to sugarbeets this year and said the prospects for the 1987 cane sugar crop also are good. Dave Carter, president of the U.S. beet sugar association, said plantings may be up in two major beet growing states, California and Michigan, while sowings could be down slightly in the largest producing state of Minnesota. Overall, Carter predicted beet plantings would rise in the midwest, and this coupled with increases in California would increase U.S. sugarbeet plantings slightly from the 1.232 mln acres sown last year. A consultant representing Florida and Texas cane growers, said Florida cane is off to a good start  because for the first time in several years there was no winter freeze. Although area to be harvesteed is about the same as last year, cane production may be up in Florida this year, he said. Reliability prediction is one of the most common forms of reliability analysis and the predict the failure rate of components and overall system reliability. It also uses an architecture based approach which is essential to predict the reliability and performance of heterogeneous systems. SMERFS [CUBED]: The purpose of developing SMERFS was that the software reliability methodology required sophisticated numerical procedures to obtain estimates of the model parameters. The acreage planted to sugarbeets will receive more than the usual amount of attention this year because of mounting concern that continued increases in domestic sugar production threaten the U.S. sugar program, industry sources said. The increases in beet plantings have especially caused concern among cane growers who have not expanded plantings, particularly in Hawaii, industry officials said."We haven't had a good weather year throughout the beet and cane areas in more than five years," said Godfrey, adding that the U.S. may be due for a good weather year. SMERFS CUBED is an application that allows the users to do hardware, software or total system reliability analysis. SMERFS CUBED aims to provide and thus allows the user to do both component and systems level assessment.The reliability of the software is predicted based on the following inputs: You may have already taken a look at my previous blog post, where we talked about machine learning and training the classifier without treating the text. Today I’m going to dig deeper into machine learning, as a follow-up to my last blog post. We’ll focus on text-processing techniques to enhance the quality of the classifier output. By acting on the quality of the training data, we can change what is called the accuracy of the classifier. Let’s get started!,Architecture of the software: The input given here is the specification of how the modules in the software interact with each other. This can be depicted with the help of state transition between the module and transfer of control. Failure Behavior: This attribute is used to define the failure behavior of the components. SMERFS [CUBED]: SMERFS CUBED provides software, hardware and system reliability analysis, the inputs are given in the form of a data set as follows: Software analysis: To do a reliability analysis based on the time between errors the input format is of two columns: elapsed time and whether a software failure has occurred. To do a reliability analysis based on the Interval Counts the input format is of two columns: Software error count and the length of the interval. Based on the input of the data, the tool gives a list of models that could be a proper fit for their data and also gives the models that cannot fit. On selecting a particular model, the tool the provides estimation of the data for the model, predictions like remaining number of errors, mean time-to-failure, expected number of fault detections over the next testing period, projected operational reliability. And also plots the original data to the predicted data. The tool also provides an accuracy for the data and the accuracy of the fit when each model is used. SREPT: The ENHPP techniques described in SREPT assume instantaneous debugging of the faults detected during the tests which is unrealistic and causes estimates that are optimistic."""
    # document3 = """INTRODUCTION The following essay compares the two reliability prediction techniques \xe2\x80\x93 Software Reliability Estimation and Prediction tool and Statistical Modeling and Estimation of Reliability Functions for Systems tool. Reliability prediction is one of the most common forms of reliability analysis and the predict the failure rate of components and overall system reliability. These predictions can then help in the evaluation of the design feasibility,  chairman of the House agriculture subcommittee responsible for the sugar program, has threatened to offer legislation next year to curb domestic sweetener output if growers fail to restrain output in 1987. SMERFS CUBED is an application that allows the users to do hardware, software or total system reliability analysis. The black box approach treats the software as one entity and does not take into consideration the internal structure of the software. The Black Box based approach predicts the results based on the following inputs: Complexity metrics: Example: lines of code, number of decisions, loops, mean length of variable names and other such static attributes of the code. Test Coverage: The ratio of potential fault sites that the test cases covered in the code to the total number of potential fault sites in the code. Inter-failure Times data: This is the observed times between failures. Architecture Based Approach:  This approach uses the internal control structure of the software.  The reliability of the software is predicted based on the following inputs: Architecture of the software: The input given here is the specification of how the modules in the software interact with each other. This can be depicted with the help of state transition between the module and transfer of control. Failure Behavior: This attribute is used to define the failure behavior of the components.evenly over the growing season, said Luther Markwart, executive vice president of the American sugarbeet growers association."The banks are putting a lot of pressure on these guys,"  SMERFS [CUBED]: SMERFS CUBED provides software, hardware and system reliability analysis, the inputs are given in the form of a data set as follows: Software analysis: To do a reliability analysis based on the time between errors the input format is of two columns: elapsed time and whether a software failure has occurred. To do a reliability analysis based on the Interval Counts the input format is of two columns: Software error count and the length of the interval.  You may have already taken a look at my previous blog post, where we talked about machine learning and training the classifier without treating the text. Today I’m going to dig deeper into machine learning, as a follow-up to my last blog post. We’ll focus on text-processing techniques to enhance the quality of the classifier output. By acting on the quality of the training data, we can change what is called the accuracy of the classifier. Let’s get started! Hardware Analysis: To do a reliability analysis based on the time between errors the input format is of five columns: time between the failure, the failure type, the severity level and the hardware number and the hardware efficiency factor between 0 and 1. System Analysis: To do a reliability analysis based on the time between errors the input format is of three columns: time between the failure, the failure type, the have especially caused concern among cane growers who have not expanded plantings, particularly in Hawaii, industry officials said."We haven't had a good weather year throughout the beet and cane areas in more than five years," said Godfrey, adding that the U.S. may be due for a good weather year. Rep. Jerry Huckaby, D-La  severity level. the average time spent in a component and the time to completion. The tool also allows the user to plot the results based on what has been detected and the predictions of the tool. SMERFS [CUBED]: Based on the input of the data, the tool gives a list of models that could be a proper fit for their data and also gives the models that cannot fit. On selecting a particular model, the tool the provides estimation of the data for the model, predictions like remaining number of errors, mean time-to-failure, expected number of fault detections over the next testing period, projected operational reliability. And also plots the original data to the predicted data. The tool also provides an accuracy for the data and the accuracy of the fit when each model is used. ASSUMPTIONS: SREPT: The ENHPP techniques described in SREPT assume instantaneous debugging of the faults detected during the tests which is unrealistic and causes estimates that are optimistic."""
    document3 ="""INTRODUCTION The following essay compares the two reliability prediction techniquanalysis and the predict the failure rate of components and overall system reliability. These predictions can then help in the evaluation of the design feasibility, comparison of the other design alternatives there are, identify the failure areas as well track the  And also plots the original data to the predicted data. The tool also provides an accuracy for the data and the accuracy of the fit when each model is used. ASSUMPTIONS:
SREPT: The ENHPP techniques described in SREPT assume instantaneous debugging of the faults detected during the tests which is unrealistic and causes estimates that are optimistic.Representatives of U.S. sugar grower organizations said they expect some increase the area planted to sugarbeets this year and said the prospects for the 1987 cane sugar crop also are good. Dave Carter, president of the U.S. beet sugar association, said plantings may be up in two major beet growing states, California and Michigan, while sowings could be down slightly in the largest producing state of Minnesota. Overall, Carter predicted beet plantings would rise in the midwest, and this coupled with increases in California would increase U.S. sugarbeet plantings slightly from the 1.232 mln acres sown last year. USDA later today releases its first estimate of 1987 U.S. sugarbeet plantings in the prospective plantings report. The main reason for the expected increase in beet sowings is that returns from competing crops such as soybeans and grains are "just awful," said Carter. In the midwest, bankers are strongly encouraging farmers to plant sugarbeets because the U.S. sugar program offers a loan rate of 18 cents per pound and because payments to farmers from beet processors are spread evenly over the growing season, said Luther Markwart, executive vice president of the American sugarbeet growers association."The banks are putting a lot of pressure on these guys," Markwart said. In some areas there are waiting lists of farmers seeking a contract with processors to plant beets, Markwart said. USDA's report today will not include any harvested area estimates for sugarcane, but representatives of Florida, Hawaii and Louisiana growers said crop prospects are good. Horis Godfrey, a consultant representing Florida and Texas cane growers, said Florida cane is off to a good start  because for the first time in several years there was no winter freeze. Although area to be harvesteed is about the same as last year, cane production may be up in Florida this year, he said. In Hawaii, area harvested may decline slightly this year, but likely will be offset again in 1987 by increased yields, said Eiler Ravnholt, vice president of the Hawaiian Sugar Planters Association. The acreage planted to sugarbeets will receive more than the usual amount of attention this year because of mounting concern that continued increases in domestic sugar production threaten the U.S. sugar program, industry sources said. The increases in beet plantings have especially caused concern among cane growers who have not expanded plantings, particularly in Hawaii, industry officials said."We haven't had a good weather year throughout the beet and cane areas in more than five years," said Godfrey, adding that the U.S. may be due for a good weather year. Rep. Jerry Huckaby, D-La., chairman of the House agriculture subcommittee responsible for the sugar program, has threatened to offer legislation next year to curb domestic sweetener output if growers fail to restrain output in 1987.reliability improvement. SREPT: Many tools that are me to completion. The tool also allows the user to plot the results based on what has been detected and the predictions of the tool. SMERFS [CUBED]:
Based on the input of the data, the tool gives a list of models that could be a proper fit for their data and also gives the models that cannot fit. On selecting a particular model, the tool the provides estimation of the data for the model, predictions like remaining number of errors, mean time-to-failure, expected number of fault detections over the next testing period, projected operational reliability."""
    text = pre_processing(document1)
    occurences,count = create_hash_count(text)
    match_text = pre_processing(document3)
    match_occurences, match_count = create_hash_count(match_text)
    max = 9
    score = 0
    sim_arr_a = {}
    for itr in count.keys():
        if max < 0:
            break
        word = itr
        if(word in match_occurences):
            a = occurences[word]
            b = match_occurences[word]
            temp_a = []
            temp_b = []
            p = 0
            q = 0
            size = min(len(a),len(b))
            while(p<size):
                i = a[p]
                temp_a += text[i-10:i+10]
                p += 1
            while (q<size):
                j = b[q]
                temp_b += match_text[j-10:j+10]
                q += 1
            temp_a = ' '.join(temp_a)
            temp_b = ' '.join(temp_b)
            sim_hash_a = Simhash(get_features(temp_a))
            sim_hash_b = Simhash(get_features(temp_b))
            sim_arr_a[word] = Simhash(sim_hash_a).distance(sim_hash_b)
            max -= 1
    return sim_arr_a

#### TO FIND SIMILARITY BETWEEN TWO DOCUMENTS ####
def find_similarity(doc1="",doc2=""):
    document1 = read_from_file(doc1)
    document2 = read_from_file(doc2)
    text = pre_processing(document1)


    ### GET OCCURENCE OF EACH WORD IN A HASHMAP AND GET THE FREQUENCY OF EACH WORD IN DOCUMENT 1####
    occurences,count = create_hash_count(text)
    match_text = pre_processing(document2)



    ### GET OCCURENCE OF EACH WORD IN A HASHMAP AND GET THE FREQUENCY OF EACH WORD IN DOCUMENT 1####
    match_occurences, match_count = create_hash_count(match_text)
    ## max is to get maximum 9 words matching ###
    max = 9
    score = 0
    sim_arr_a = {}
    for itr in count.keys():
        if max < 0:
            break
        word = itr
        if(word in match_occurences):
            a = occurences[word]
            b = match_occurences[word]
            temp_a = []
            temp_b = []
            p = 0
            q = 0
            size = min(len(a),len(b))
            while(p<size):
                i = a[p]
                temp_a += text[i-10:i+10]
                p += 1
            while (q<size):
                j = b[q]
                temp_b += match_text[j-10:j+10]
                q += 1
            temp_a = ' '.join(temp_a)
            temp_b = ' '.join(temp_b)
            sim_hash_a = Simhash(get_features(temp_a))
            sim_hash_b = Simhash(get_features(temp_b))
            sim_arr_a[word] = Simhash(sim_hash_a).distance(sim_hash_b)
            max -= 1
    ### RETURN THE DICTIONARY OF EACH WORD WITH SCORE ###
    return sim_arr_a


def calculate_score():

    scores = main_method()
    sa = scores.values()
    sum = 0
    for itr in sa:
        sum += itr
    avg = sum/len(sa)
    return sum,avg,scores


def read_from_file(file_name):
    with open(file_name) as f:
        lines = f.read().splitlines()
    return ' '.join(lines)

def analysis_report():
    pass



def get_features(s):
    width = 3
    s = s.lower()
    s = re.sub(r'[^\w]+', '', s)
    return [s[itr:itr + width] for itr in range(max(len(s) - width + 1, 1))]

